# -*- coding: utf-8 -*-
"""DnCNN_based_generate_prnu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1304KvoXmdJ7viy8Z_1a2SYFIkcIwMcVa
"""

import torch
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch import optim
import torchvision.models as models
import torch.nn as nn
import torch.nn.functional as F
from torchsampler import ImbalancedDatasetSampler
from collections import OrderedDict

import numpy as np
import os
from tqdm import tqdm
import gc
# plot
import matplotlib.pyplot as plt
import cv2

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print("device:", device)

class dataset(Dataset):
    def __init__(self, root, traintest) -> None:
      super().__init__()
      self.root = root
      self.training_set = []
      if traintest == "train":
        for i, camera in enumerate(os.listdir(root)):
          images = np.load(root + camera)
          images_len = len(images)
          for image in images[:int(images_len*0.7)]:
            information = {
              'image':torch.tensor(image),
              'target':torch.tensor(int(camera.split('.')[0].split('_')[2]))
              }
            self.training_set.append(information)
      elif traintest == "val":
          for i, camera in enumerate(os.listdir(root)):
            images = np.load(root + camera)
            images_len = len(images)
            for image in images[int(images_len*0.6):int(images_len*0.8)]:
              information = {
                'image':torch.tensor(image),
                'target':torch.tensor(int(camera.split('.')[0].split('_')[2]))
                }
              self.training_set.append(information) 
              
      elif traintest == "test":
        for i, camera in enumerate(os.listdir(root)):
          images = np.load(root + camera)
          images_len = len(images)
          for image in images[int(images_len*0.7):]:
            information = {
              'image':torch.tensor(image),
              'target':torch.tensor(int(camera.split('.')[0].split('_')[2]))
              }
            self.training_set.append(information)
    def __getitem__(self, index):
      return self.training_set[index]
    
    def __len__(self):
      return len(self.training_set)
    
    def get_labels(self):
      return [int(item['target']) for item in self.training_set]

root = '/content/drive/MyDrive/data/'
training_set = dataset(root, 'train')
train_dataloader = DataLoader(training_set, batch_size=4, sampler=ImbalancedDatasetSampler(training_set))
val_set = dataset(root, 'val')
val_dataloader = DataLoader(val_set, batch_size=4, sampler=ImbalancedDatasetSampler(val_set))
test_set = dataset(root, 'test')
test_dataloader = DataLoader(test_set, batch_size=4)

prnudatas = dict(zip(range(35), [None for _ in range(35)]))
prnuroot = '/content/drive/MyDrive/FlatPRNU/'
for i, prnu_name in enumerate(os.listdir(prnuroot)):
  prnu = np.load(prnuroot + prnu_name)
  prnudatas[i] = prnu

import basicblock as B

class DnCNN(nn.Module):
    def __init__(self, in_nc=3, out_nc=3, nc=64, nb=17, act_mode='BR'):
        super(DnCNN, self).__init__()
        assert 'R' in act_mode or 'L' in act_mode, 'Examples of activation function: R, L, BR, BL, IR, IL'
        bias = True

        m_head = B.conv(in_nc, nc, mode='C'+act_mode[-1], bias=bias)
        m_body = [B.conv(nc, nc, mode='C'+act_mode, bias=bias) for _ in range(nb-2)]
        m_tail = B.conv(nc, out_nc, mode='C', bias=bias)

        self.model = B.sequential(m_head, *m_body, m_tail)

    def forward(self, x):
        x = self.model(x)
        return x

model = DnCNN().to(device)

mse_loss = nn.MSELoss()

learning_rate = 0.001
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

def train(model, train_dataloader, optimizer, loss_fn, epoch):
    model.train()
    loss_total = 0
    count = 0
    
    for i, data in enumerate(train_dataloader):
      # traing data
      image = data['image'].type(torch.FloatTensor).to(device)
      image = image.permute(0, 3, 2, 1)
      #image = (image - image.min())/(image.max() - image.min())
      image = torch.abs(image)
      #image = torch.where(image > 0, 0, image)
      #print(image)

      ## Target
      target = data['target']
      truth = torch.tensor([prnudatas[int(item)] for item in target])
      #truth = truth.unsqueeze(1)
      truth = truth.repeat(1, 3, 1, 1)
      #truth = (truth - truth.min())/(truth.max() - truth.min())
      truth = torch.abs(truth)
      #truth = torch.where(truth > 0, 0, truth)
      truth = truth.to(device)
      
      

      ##
      optimizer.zero_grad()
      output = model(image)
      loss = loss_fn.forward(output, truth)
      loss.backward()

      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01) 
      optimizer.step()
      loss_total += loss
      count += 1
      #break


    print(f"Epoch {epoch:3d}  | loss: {loss_total/count:8.3f}")
    return loss_total/count

def val(model, train_dataloader, optimizer, loss_fn, epoch):
    model.eval()
    loss_total = 0
    count = 0
    
    for i, data in enumerate(train_dataloader):
      # traing data
      image = data['image'].type(torch.FloatTensor).to(device)
      image = image.permute(0, 3, 2, 1)
      #image = image + 1

      ## Target
      target = data['target']
      truth = torch.tensor([prnudatas[int(item)] for item in target])
      truth = truth.repeat(1, 3, 1, 1)
      truth = truth.to(device)
      
      

      ##
      output = model(image)
      loss = loss_fn.forward(output, truth)
      loss_total += loss
      count += 1
      #break


    print(f"Epoch {epoch:3d}  | loss: {loss_total/count:8.3f}")
    return loss_total/count

EPOCH = 4000
loss = []
j = 1
for epoch in tqdm(range(EPOCH)):
  loss.append(train(model, train_dataloader, optimizer, mse_loss, epoch))
  #val(model, val_dataloader, optimizer, mse_loss, epoch)
  # if j%10 == 0:
  #   scheduler.step()
  # j += 1

torch.save(model, '/content/drive/MyDrive/g_model_5.pt')

import matplotlib.pyplot as plt
val_losses = []
train_losses = []
plt.figure(figsize=(10,5))
plt.title("Training Loss")
plt.plot([item.cpu().detach().numpy() for item in loss], label="train")
plt.xlabel("Epoches")
plt.ylabel("Loss")
plt.legend()
plt.show()

def test(model, test_dataloader):
  model.eval()
  loss_total = 0
  count = 0
  
  for i, data in enumerate(test_dataloader):
    image = data['image'].type(torch.FloatTensor)
    image = image.permute(0, 3, 2, 1)
    i_min, i_max = image.min(), image.max()
    image = (image - image.min())/(image.max() - image.min())
    image = image.to(device)

    #print(image)

    target = data['target']
    truth = torch.tensor([prnudatas[int(item)] for item in target])
    truth = truth.repeat(1, 3, 1, 1)
    t_min, t_max = truth.min(), truth.max()
    #truth = (truth - t_min)/(t_max - t_min)
    truth = truth.to(device)

    output = model(image)
    output = output * (t_max - t_min) + t_min
    # print('1:',output[0][0][0])
    # print('2:', truth[0][0][0])
    # print()
    loss = mse_loss.forward(output, truth)
    loss_total += loss.item()
    count += 1


  print(f"loss: {loss_total/count:8.3f}")
  return loss_total/count

test(model, test_dataloader)

model.eval()
outputs = {0:[], 1:[], 2:[], 3:[], 4:[], 6:[], 11:[], 16:[], 20:[], 23:[]}
for i, data in enumerate(test_dataloader):
  image = data['image'].type(torch.FloatTensor).to(device)
  image = image.permute(0, 3, 2, 1)
  image = torch.abs(image)
  i_min, i_max = image.min(), image.max()
  image = (image - image.min())/(image.max() - image.min())
  target = data['target']

  truth = torch.tensor([prnudatas[int(item)] for item in target])
  t_min, t_max = truth.min(), truth.max()

  output = model(image)
  output = output * (t_max - t_min) + t_min
  for j, item in enumerate(target):
    outputs[int(item)].append(output[j].cpu().detach().numpy())

for i in outputs.keys():
  np.save('/content/drive/MyDrive/new_prnu_1/res_noise_'+str(i)+'.npy', np.array(outputs[i]))